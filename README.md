# Matrice_AI_Coding_Assessment
The Coding Assessment includes two different tasks. One is Object detection (bounding box) and instance segmentation. In object detection, we assign a class label to bounding boxes that contain objects. Instance Segmentation involves classifying each pixel or voxel of a given image or volume to a particular class and assigning a unique identity to the pixels of individual objects.

There are two files in this repository. One is colab notebook, that contains code for data creation, model creation , model training and model inference. The other file, which is with '.pdf' extension is documentation of my solution.

The evaluation metrics for the Deep Fashion dataset reveal promising performance across various aspects of object detection and segmentation. With a mean Average Precision (mAP) of 0.8984 for bounding boxes and 0.8917 for masks, the model demonstrates strong capability in accurately localizing and segmenting objects within images. However, the mAP values drop slightly to 0.7362 (bounding boxes) and 0.6205 (masks) when considering a wider confidence interval of 50% to 95%, indicating a reduced performance margin at higher confidence thresholds. Precision scores of 0.8084 (bounding boxes) and 0.8258 (masks) suggest a high level of accuracy in object detection, while recall rates of 0.8228 (bounding boxes) and 0.8151 (masks) indicate effective retrieval of relevant objects within the dataset.

On the training front, the model exhibits reasonable loss values across different components. The Box Loss stands at 0.2936, indicating a relatively low discrepancy between predicted bounding box coordinates and ground truth annotations. Segmentation Loss, with a value of 0.825, signifies the model's ability to accurately delineate object boundaries. Classification Loss (Cls loss) is recorded at 0.2758, indicating efficient classification of objects into respective categories. Additionally, the model incurs a Dfl (Domain-Friendly Loss) of 0.8788, reflecting its adaptability and performance across different domains
